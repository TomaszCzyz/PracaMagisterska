%%% & --translate-file=cp1250pl
%% ************ AKADEMIA GÓRNICZO-HUTNICZA W KRAKOWIE **************
%% ***************** Wydział Matematyki Stosowanej ***************** 
%% ****************** PRACA MAGISTERSKA w LaTeX-u ******************
%%    autor: Tomasz Czyż
%%    Copyright (C) 2003 by ------
%% ************************* Plik główny *************************

%%
%% ======== PREAMBUŁA ======== 
%%
\documentclass[oik, pdftex, robocza, man]{mgrwms}

\usepackage[utf8]{inputenc}  % opcja latin2 dla Linux
\usepackage{amsmath}           % łatwiejszy skład matematyki
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\DeclareMathOperator*{\esssup}{ess\,sup}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{latexsym}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{mathtools}

\usepackage{color}

\usepackage[polish]{babel}
\usepackage[OT4]{fontenc}
\usepackage{polski}
\allowdisplaybreaks
%% <<<< BiBTeX >>>>
% \bibliographystyle{ddabbrv}
% \nocite{*}


\begin{document}
%%
%% ======== METRYCZKA PRACY ========
%%
\title{ \LARGE Aproksymacja funkcji kawałkami regularnych przy użyciu informacji dokładnej i niedokładnej}
\author{Tomasz Czyż}
\promotor{dr Maciej Goćwin}
\nralbumu{290565}
\maketitle

\slowakluczowe{słowa kluczowe}
\keywords{keywords}
%%
%% ======== MAKRA ========
%%
%-> Miejsce na nasze makra (jedno z wielu ;). Lepszym pomysłem będzie jednak 
%-> umieszczenie ich w osobnym pliku i wczytanie poleceniem \input
%%
\newtheorem{thm}{Twierdzenie}[chapter]
\newtheorem{lemma}[thm]{Lemat}
\newtheorem{stw}[thm]{Stwierdzenie}
\newtheorem{cor}[thm]{Wniosek}
\newtheorem{obs}[thm]{Obserwacja}
\newtheorem{uw}[thm]{Uwaga}
\newtheorem{df}[thm]{Definicja}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Pra}{\mathbb{Pra}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{G^{r,\varrho}([a,b])}
\newcommand{\1}{\mathbbm{1}}

\makeatletter
\newcommand*{\defeq}{\mathrel{\rlap{%
                     \raisebox{0.3ex}{$\m@th\cdot$}}%
                     \raisebox{-0.3ex}{$\m@th\cdot$}}%
                     =}
\let\c@table\c@figure
\makeatother

%%
%% ======== SPIS TREŚCI ========
%%

\tableofcontents

%%
%% ======== STRESZCZENIE PRACY (POLSKIE) ========
%%

\begin{streszczenie}
    Streszczenie
\end{streszczenie}

%%
%% ======== STRESZCZENIE PRACY (ANGIELSKIE) ========
%%

\begin{abstract}
    Abstract
\end{abstract}

%%
%%
%% ======== GŁÓWNA CZĘŚĆ PRACY ========
%%
%%

%%
%% ==== WSTĘP ====
%%

\begin{wstep}[Wprowadzenie]
    Aproksymacja funkcji oparta na dostępnej inforamcji jest problemem badanym od lat. Powstają coraz bardziej zaawansowane algorytmy, działające przy coraz słabszych założeniach o funkcji. Często jednak w rozważaniach teoretycznych pomijany jest czynnik zewnętrzny, który może powodować zaburzenia dostępych informacji. W tej pracy pokazujemy, jak znaczący wpływ na wyniki numeryczne może mieć zaniedbanie tego faktu.

    W tym celu przedstawimy dwa algoytmy z artukułów \cite{AoP} i \cite{CoDF}. Pierwszy z nich bazuje na wielomianach Lagrnage'a i jego analiza nie uwzględnia zaburzenia danych wejściowych. Algorytm z \cite{AoP} dopuszcza informacje niedokładną, a kluczowy krok opiera się na różnicach dzielonych. 

    Omwiane algorytmy aprkosymują funkcje kawałkami regularne. Mówimy, że funkcja skalarna $g$ jest $(r, \varrho)$-regularna na przedziale $[a,b]$, jeśli $g \in C^{r}([a,b])$ oraz $g^{r}$ jest Hölderowsko ciągła z wykładnikiem $\varrho \in (0,1]$. Rozważmy przestrzeń $F_{r,\varrho}$ $T$-okresowych funkcji $f$, które składają się z dwóch $(r,\varrho)$-regularnych części oddzielonych nieznanym punktem osobliwym $s_{f}$.
    
    Oba algorytmy osiągają ten sam minimalny błąd najgorszego przypadku proporcjonalny do $n^{-(r + \varrho)}$ dzięki zastosowaniu adaptacji. Adaptacyjny wybór punktów siatki jest niezbędny, aby otrzymać taki błąd. Ograniczenia związane z algorytmami nieadaptacyjmymi zostały omówione w \cite{UA}, \cite{PoA} oraz [?] (...).

    %Poswstało już wiele prac dotyczących aproksymacji funkcji. Badano funkcje regularne i takie z osobliwościami. Niektóre z prac zakładały posiadnie kompletnej inforamcji o przybliżanej funkcji, niektóre tylko do ograniczonej libczy jej wartości. Rozważano zarówno algorytmy adaptacyjne, jak i nieadaptacyjne. Jednak znacznie mniej prac skupiało się na informacji niedokładnej

    % Celem niniejszej pracy jest analiza algorytmu aproksymującego funkcje kawałkami gładkie, który 
    %Celem niniejszej pracy jest analiza zachowania różnych algorytmów aproksymujących funkcje kawałkami gładkie przy użyciu informacji dokładniej i niedokładniej.
    % Pierwszy z analizowanych algorytmów został przedstawiony w pracy \cite{PoA}. Rozważane są w niej funkcje klasy $F^{\infty}_r$, o których zakładamy, że zarówno sama funkcja $f: [0,T] \longrightarrow \R$ może być nieciągła, jak i jej pochodna, począwszy od rzędu możliwe większego od pierwszego. Czyli, dla przykładu, $f$ może być dwa razy różniczkowalna na $[0, T]$ i $f^{(3)}(s)$ może nie istnieć w jakimś punkcie $s$. Ponadto, $f$ może mieć skończenie wiele punktów osobliwych; ich ilość i położenie jest nieznane. Dodatkowo, algorytm przedstawiony w \cite{PoA} używa $n$ wartości funkcji w punktach $x_1, \ldots x_n$ jako jedyne dostępne informacje o funkcji $f$, a w przypadku algorytmu adaptacyjnego dopuszczamy, że wybór $x_j$ zależy od $f(x_1), \ldots, f(x_{j-1})$.
    % W wymienionej pracy do znalezienia optymalnego algorytmu nieadaptacyjnego i adaptacyjnego w najgorszym przypadku oraz w przypadku asymptotycznym do mierzenia błędu stosowana jest m.in. norma $L^p (1 \leq  p < \infty)$.

    % W artykule \cite{UA} rozszerzony jest wynik prac \cite{IaA} i \cite{PoA} poprzez skupienie się na klasie funkcji ciągłych globalnie r-regularnych z co najwyżej jednym punktem osobliwym. W podanej pracy przedstawiony jest algorytm nieadaptacyjny, który asymptotycznie poprawia ograniczenie błędu z \cite{AoP}.

    % Ostatni z analizowanych algorytmów pochodzi z pracy \cite{AoP} i jako jedyny z przedstawionych algorytmów uwzględnia zaburzenie danych. W artykule uogólnione zostają rezultaty z \cite{PoA} i \cite{UA} poprzez wprowadzanie informacji niedokładniej oraz założenie, że wykładnik Höldera $\varrho \in (0,1]$. (...) Z tego powodu w pracy \cite{AoP} przedstawiony został nowy algorytm do lokalizacji osobliwości. Co więcej dla $\varrho = 0$, co odpowiada informacji dokładniej, przedstawiony algorytm jest nawet prostszy niż te z \cite{PoA} i \cite{UA}.

\end{wstep}


\chapter{Definicje}

\section{Informacja, algorytm, aproksymacja}

    W tym rozdziale wyjaśnijmy co rozumiemy przez aproksymacje i w jaki sposób ją otrzymujemy. W tym celu wprowadzimy fundamentalne pojęcia, takie jak operator rozwiązania, informacja zaburzona oraz algorytm. Szczególną uwagę poświęcimy informacji, która jest najważniejszym czynnikiem naszej analizy. Informacja, mowiąc w skrócie, jest tym co wiemy o problemie do rozwiązania. W niniejszej pracy kluczownym założeniem jest to, że informacja jest \textit{zaburzona}, to znaczy, nie jest dokładna, czyli ma jakiś błąd.

    Niech $F$ będzie przestrznią liniową a $G$ przestrzenią unormowaną, obie nad ciałem liczb rzeczywistych. Odwzorowanie 
    \begin{equation*}
        S : F \rightarrow G
    \end{equation*}
    nazywamy \textit{operatorem rozwiązania}. Dla każdego elementu $f$ z $F$ chcemy obliczyć aproksymację $S(f)$. Niech $U(f)$ będzie obliczoną aproksymacją.

    Niech $\varepsilon \geq 0$. Mówimy, że $S(f)$ jest $\varepsilon$-aprkosymacją funkcji $f$ wtw, gdy $\| S(f) -  U(f)\| \leq \varepsilon$. Celem jest znalezienie takiej aproksymacji $U(f)$, że jest ona $\varepsilon$-aprkosymacją dla wszysktich elementów $f$ z $F$. Aby to zrobić potrzebujemy posiadać pewną wiedzę $f$.

    \textit{Operatorem informacji (lub informacją)} nazywamy odwzorowanie
    \begin{equation*}
        N : F \rightarrow 2^{Y},
    \end{equation*}
    gdzie Y jest zbiorem skończonych ciągów liczb rzeczywistych, $ Y \subset \bigcup^{\infty}_{n=1} \R^{n}$, czyli $N(f)$ jest pozbiorem $Y$.
    Na ogól nie mamy dostępu do pełnej wiedzy o funkcjii, dlatego musimy założyć, że możemy zbierać informacje o $f$ poprzez formę (?tłum?) $L(f)$, gdzie $L : F \rightarrow H$ dla pewnego zbioru $H$.
    
    Przez $\Lambda$ oznaczmy klasę dopuszczalnch operacji $L$, czyli $L \in \Lambda$ wtw, gdy $L(f)$ może zostać obliczone dla każdego elementu $f$ z $F$. Rozważmy teraz dwa sposoby doboru inforamcji. Jeśli informacja $N$ jest liczona dla każdego $f$ niezależnie, to taką informację nazywamy nieadaptacyjną. Innymi słowy, inforamcja $N$ jest nieadaptacyjna wtw, gdy istnieje $L_{1}, \ldots, L_{n} \in \Lambda$ takie, że
    \begin{equation*}
        N(f) = \left[ L_{1}(f), L_{2}(f), \ldots, L_{n}(f) \right] \; \forall f \in F.
    \end{equation*}
    Inna klasą inforamcji jest informacja adaptacyjna, w której możemy wybierać wartości bazując na poprzednich wynikach. Mówiąc dokłądniej, informacja $N$ jest adaptacyjna wtw, gdy
    \begin{equation*}
        N(f) = \left[ L_{1}(f), L_{2}(f; y_{1}), \ldots, L_{i}(f; y_{1}, \ldots, y_{n(f)-1}) \right],
    \end{equation*}
    gdzie $y_{1} = L(f_{1})$ i $y_{i} = L_{i}(f; y_{1}, y_{2}, \ldots, y_{i-1})$ dla $i=2,3,\ldots,n(f)$. Musimy również założyć, że $L_{i}(\cdot;y_{1}, \ldots, y_{i-1})$ należą do operacji dozwolonych. W przypadku informacji adaptacyjnej nie możemy z góry określić liczby operacji na problemie $f$, ponieważ jest to dynamicznie ustalne podczas procesu oblicznia kolejnych wartości $y_{i}$.

    Warto zauważyć, że jeśli rozważany problem wymaga obliczenia bardzo dużej ilości informacji o funkcji w krótkim czasie, to zastosowanie informacji nieadaptacyjnej może przyśpieszyć oblicznienia, ze względu na możliwość zrównoleglenia obliczeń. W przypadku adaptacyjnym kolejność obliczeń ma znaczenie, więc informacje musimy pozyskiwać sekwencyjnie.

    Możemy zapisać informacje nieadaptacyjną i adaptacyjną zakładając, że $f$ jest funkcją oraz $N(f) = \left[ f(t_{1}), f(t_{2}), \ldots, f(t_{n(f)}) \right]$. Jeżeli $n(f) = n$ i punkty $t_{i}$ otrzymujemy \textit{a priori}, wtedy $N$ jest nieadaptacyjna. Natomiast, jeżeli $n(f)$ różni się lub wybór punktów $t_{i}$ jest zależny od $f(t_{1}), f(t_{2}), \ldots, f(t_{i})$, to $N$ jest adaptacyjna.

    Kolejnym kluczowym założeniem jest fakt, że informacje o funkcji zazwyczaj uzyskujemy z pewnym błędem. Mówiąc dokłądniej, inforamcje o funkcji przyjmują postać $y_{i} = f(x_{i}) + e_{i}$, dla $1 \leq i \leq n$, gdzie $e_{i} \leq \delta$ nazywamy \textit{szumem}.
    
    Dla przykładu, dla informacji nieadaptacyjnej składającej się z zaburzonych ewaluacji funkcji $f$ w punktach $x_{1}, \dots, x_{n}$ z precyzją $\delta$, mamy:
    \begin{equation*}
        N(f) = \{y \in \R^{n} : \quad |y_{i} - f(x_{i})| \leq \delta, \quad 1 \leq i \leq n\}
    \end{equation*}
    
    Każdy element $y \in N(f)$ będziemy nazywać \textit{informacją o $f$}. Zauważmy, że dla $\delta = 0$, zbiór $N(f)$ ma dokładnie jeden element dla wszystkich $f \in F$, tzn. informacja $N$ jest \textit{dokładna}. Zakładamy, że $N(f)$ jest niepuste dla wszystkich $f \in F$. W przypadku, gdy istnieje $f$ dla którego $N(f)$ ma przynajmniej dwa elementy, wtedy informacja jest \textit{niedokładna(częściowa)}.

    Naszym zadaniem jest aproksymacja elementów $S(f)$ dla $f$ należącego do $E \subset F$, bazując wyłącznie na informacji zaburzonej o $f$. 

    Znając informację $y$ o $f$ możemy wprowadzić aproksymację, a dokłanie algorytm, który ją wyprodukuję. \textit{Algorytmem} nazywamy odwzorowanie:
    \begin{equation*}
        \varphi : Y \rightarrow G
    \end{equation*}
    Innymi słowy, aproksymacją $S(f)$ jest $\varphi(y)$, gdzie $y$ jest informacją o $f$. Błąd aproksymacji zdefiniownay jest jako różnica $\| S(f) - \varphi(y) \|$, gdzie $\|\cdot\|$ jest normą w przestrzeni $G$.


\section{Model obliczeniowy}

    W ogólności, optymalność algorytmu oraz jego złożonść zależą od przyjętego modelu obliczeniowego. Model jest określony poprzez sposób w jaki błąd i koszt algorytmu są zdefiniowane. 
    
    %TODO: koszt def
    
    Jeżeli za błąd i koszt przyjmujemy wydajność na najtrudniejszym spośród wszystkich problemów w danej klasie, wtedy mówimy o \textit{modelu najgorszego przypadku}. Innymi często rozważanymi modelami są: probablistyczny, średni, mieszany, losowy czy asymptotyczny, jednak nimi nie będziemy zajmować się w tej pracy.

    Niech $N : R \rightarrow 2^{Y}$ będzie operatorem inforamcji. Poprzez \textit{błąd najgorszego przypadku} algorytmu $\varphi : Y \rightarrow G$ na zbiorze $E \subset F$ rozumiemy:
    \begin{equation*}
        e^{wor}_{p}(\phi, N, E) = \sup_{f \in E} \sup_{y \in N(f)} \|S(f) - \varphi(y) \|
    \end{equation*}

    Oznaczmy przez $\mathcal{N}(n, \delta)$ klasę wszystkich (adaptacyjnych) informacji $N$, które używają co najwyżej $n$ ewaluacji funkcji, z precyzją $\delta$ każda. Wtedy przez \textit{minimalany błąd najgorszego przykładu} w klasie $E$, który może zostać osiągnięty przez algorytm używający informacji o co najwyżej $n$ wartościach funkcji z precyzją $\delta$ rozumiemy:

    \begin{equation*}
        r^{wor}_{p}(n, \delta, E) = \inf\{ e^{wor}_{p}(\varphi, N, E) : \; \varphi \; uzywa \; N \in \mathcal{N}(n, \delta) \}
    \end{equation*}

    W tej pracy porównujemy dwa algorytmy aprksymujęce funkcje z osobliwością, które osiągają to samo, optymalne organiczenie na minimalny błąd najgorszego przypadku, jednak tylko w przypadku jednego z nich w analizie zostało uwzgędione zaburzenie.

\section{Klasy funkcji}

    Dla liczby całkowitej $ r \geq 0$, $\varrho \in (0,1]$ oraz $a < b$, przez $H_{r, \varrho}(a,b)$ oznaczamy przestrzeń funkcji $g: [a,b] \rightarrow \R$ takich, że $g \in C^r([a, b])$ i $g^{(r)}$ jest Hölderowsko ciągła z wykładnikiem $\varrho$, tzn.
    \begin{equation*}
        c(g) := \sup_{a \leq x \leq y \leq b} \frac{|g^{(r)}(x) - g^{(r)}(y)|}{|x-y|^{\varrho}} < \infty.
    \end{equation*}
    Dla danego $T > 0$ niech $F_{r, \varrho} = F_{r, \varrho}(T)$ będzie przestrzenią funkcji $f: \R \rightarrow \R$ spełniających następujące warunki: istnieje $s_f \in [0, T)$ i $g_f \in H_{r, \varrho}(0,T)$ takie, że
    \begin{equation*}
        f(lT + s_f + x) = g_f(x) \quad \text{for all} \quad l = 0, \pm 1, \pm 2, \ldots \quad \text{i} \quad x \in [0, T)
    \end{equation*}
    Można powiedzieć, że $f$ jest 'kopią' $g_f$ na każdym z przedziałów $(lT + s_f, (l + 1)T + s_f]$ i $f$ jest prawostronnie ciągła na $lT + s_f$. W związku z tym wszystkie punkty, które różnią się między sobą o wielokrotność $T$ będą uważane za identyczne. Dla przykładu, jeżeli $0 < x_1 \leq T < x_2 \leq 2T$, to przedział $(x_1, x_2]$ będzie utożsamiany z $(x_1,T] \cup (0, x_2 - T] \subset (0, T]$.

    Przez $\Delta_f^{(j)}$ ozanaczmy \emph{skoki nieciągłości} dla kolejnych pochdnych $f$ w punkcie nieciągłości $s_f$,
    \begin{equation*}
        \Delta_f^{(j)} = f^{(j)}(s_f^+) - f^{(j)}(s_f^-) = g_f^{(j)}(0) - g_f^{(j)}(T) \quad 0 \leq j \leq r,
    \end{equation*}

    W tej pracy będziemy rozpatrywać rózne aproksymacje $\varphi : Y \rightarrow L^p(0, T)$ funkcji $f \in F_{r, \varrho}$ względem normy $L^p$, gdzie $1 \leq p \leq \infty$. Czyli z definicji, błąd aproksymcji dla informacji $y$ wynosi:
    \begin{equation*}
        \|f-\varphi(y)\|_{L^p} = \left( \int_{0}^{T} |(f-\varphi(y))(x)|^p \,dx  \right)^{1/p} \qquad dla \; 1 \leq p < \infty
    \end{equation*}
    oraz
    \begin{equation*}
        \|f-\varphi(y)\|_{L^\infty} = \esssup_{0 < x \leq T} | (f - \varphi(y))(x) |
    \end{equation*}

    Rozróżniamy następujące klasy $\mathcal{F}$:
    \begin{equation*}
        \begin{split}
            \mathcal{K} & = \{f = c \1_{\R}, c \in \R \}, \\
            \mathcal{H}_{r, \varrho} & = \{ f \in F_{r, \varrho}: c(g_{f}) \leq 1, \Delta_{f}^{(j)} = 0 \; for\; all\; 0 \leq j \leq r\} \\
            \mathcal{F}_{r, \varrho}^{C} & = \{ f \in F_{r, \varrho}: c(g_{f}) \leq 1, \Delta_{f}^{(0)} = 0 \} \\
            \mathcal{F}_{r, \varrho}^{D} & = \{ f \in F_{r, \varrho}: c(g_{f}) \leq 1, | \Delta_{f}^{(0)} | \leq 1 \} \\
            \mathcal{F}_{r, \varrho} & = \{ f \in F_{r, \varrho}: c(g_{f}) \leq 1 \} \\
        \end{split}
    \end{equation*}
    Oczywiście
    \begin{equation*}
        \mathcal{K} \subset \mathcal{H}_{r, \varrho} \subset \mathcal{F}_{r, \varrho}^{C} \subset \mathcal{F}_{r, \varrho}^{D} \subset \mathcal{F}_{r, \varrho}
    \end{equation*}

\mgrclosechapter


\chapter{Ograniczenia na błąd}

    \section{Ograniczenie z dołu}

    Do określania błędu będziemy używać notacji $\varOmega$, $\varTheta$, $\mathcal{O}$, $\textit{o}$ (wersji Knutha). Gdy dwie funkcje $f$ i $g$ zdefiniowane na $\R_{+}$ i przyjmują wartości nieujemne, to piszemy $f(x) = \Omega\left( g(x) \right)$ wtedy, gdy istnieją dodatnie stałe $c_{1}$ i $c_{2}$ takie, że $f(x) \geq c_{1} g(x)$ dla $x \in [0, c_{2}]$. Przez $f(x) = \Theta\left( g(x) \right)$ rozumiemy $f(x) = \Omega\left( g(x) \right)$ and $g(x) = \Omega\left( f(x) \right)$, czyli istnieją takie stałe $c_{1}$, $c_{2}$ i $c_{3}$, że $c_{1} g(x) \leq f(x) \leq c_{2} g(x)$ dla $x \in [0, c_{3}]$. Natomiast przez $f(x) = \mathcal{O}(g(x))$ rozumiemy, że $g(x) = \Omega(f(x))$, a przez $f(x) = \textit{o}(g(x))$ rozumiemy, że $\displaystyle \lim_{x \rightarrow 0} \frac{f(x)}{g(x)} = 0$.

    W dalszej części pracy, dla rozróżnienia aproksymaji zwróconych poprzez algorytmy, posłużymy się oznaczenami pochodzącymi od pierwszych liter nazwisk autorów odpowiednich artykułów. Oznaczenie $\varphi_{KP}$ będzie odnosiło się do wyniku algorytmu z pracy \cite{CoDF}, natomiast $\varphi_{MP}$ to algorytmu z pracy \cite{AoP}.

    Poniższe ograniczenia dolne na $r^{wor}_{p}(n, \delta, \mathcal{F})$ są dość oczywiste albo mogą zostać wyprowadzone ze znanych rezultatów

    \begin{stw} \label{stw1}
        Dla każdego $n$ i $\delta \geq 0$ mamy:
        \begin{enumerate}[label=(\roman*)]
            \item \label{stw1_i} $r^{wor}_{p}(n, \delta, \mathcal{K}) \geq \delta T^{1/p}$
            \item \label{stw1_ii} $r^{wor}_{p}(n, \delta, \mathcal{H}_{r,\varrho}) \geq a_{r,\varrho}n^{-(r + \varrho)}$ dla pewnego $a_{r,\varrho} > 0$
            \item \label{stw1_iii} $r^{wor}_{p}(n, \delta, \mathcal{F}_{r,\varrho}) = \infty, \quad r \geq 1$
        \end{enumerate}
    \end{stw}
    \begin{proof}
        W celu udowodnienia \ref{stw1_i} wystarczy zauważyć, że $y = (0, \ldots, 0)$ jest informacją o funkcji stałej postaci $f_{\pm} \!=\! \pm \delta$ dla każdego $N$ z precyzją $\delta$. Wynika z tego, że error dowlonego algorytmu używającego $N$ jest równy conajmniej $\| f_{+\delta} - f_{-\delta} \|_{L^{p}} / 2 = \delta T^{1/p}$.

        Nierówność \ref{stw1_ii} wynika z znanych rezultatów dotyczących minimalnego błędu aproksymacji dla informacji dokładnej, zobacz [?].

        Aby pokazać \ref{stw1_iii}, użyjemy rozumowania podobnego do \cite{PoA} [sekcja, 5.2], gdzie przeprowadzono dowód dla $\varrho = 1$ i $\delta = 0$. Niech $S(M) \subset \F_{r, \varrho}$ będzie rodziną funkcji $f_{s}$ dla $s \in [0, T)$
        \begin{equation*}
            f_{s}(x) = \frac{M}{T}\left( x\1_{[0,s)}(x) + (x-T)\1_{[s,T)}(x) \right), \quad 0 \leq x \leq T
        \end{equation*}
        Niech $N$ będzie dowolną (adaptacyjną) informacją używającą nie więcej niż $n$ ewaluacji funkcji. Ponieważ dla każdego ustalonego $x$, funkcja $f_{s}(x)$ może przyjmować tylko dwie wartości w zależności czy $s \leq x$ lub $s > x$, to całkowita liczba punktów użytych przez $N$ dla klasy $S(M)$ wynosi co najwyżej $2^{n}-1$. Dlatego istenieje przedział $[s_{1}, s_{2}] \subset (0,T)$ o długości $T 2^{-(n-1)}$, który nie zawiera żadnego z tych punktów. To oznacza, że  $N(f_{s_{1}}) = N(f_{s_{2}})$, a więc błąd dowolnego algorytmu używającego informacji $N$ wynosi przynajmniej $\| f_{s_{1}} - f_{s_{2}} \|_{L^{p}} / 2 = \delta M(T 2^{-(n+p+1)})^{1/p}$. Z uwagi na to, że $M$ jest dowlonie duże, błąd również może być dowolnie duży.
    \end{proof}

    Z stwierdzenia \ref{stw1} \textit{\ref{stw1_i}-\ref{stw1_ii}} otrzymujemy, że 
    \begin{equation*}
        r^{wor}_{p}(n, \delta, \mathcal{F}^{D}_{r,\varrho}) \geq r^{wor}_{p}(n, \delta, \mathcal{F}^{C}_{r,\varrho}) \geq \max(\delta T^{1/p}, a_{r,\varrho} n^{-(r+\varrho)})
    \end{equation*}

    W dalszej części pracy udowodnimy, że te nierówności są ostre, z wyjątkiem pierwszej dla $p=\infty$. To jest główny wyniki artykułu \cite{AoP}, który możemy zapisać w poniższej postaci:

    \section{Ograniczenia z góry}

    Omawiane algorytmy posiadają te same ogranieczenia z góry, jednak jak wspomnieliśmy, algorytm przedstawiony w pracy \cite{CoDF} bazuje na informacji dokładnej, w przeciwieństwie do algorytmu z pracy \cite{AoP}, który uwzględnia zaburzenie danych. Ta różnica wpłynęła na to, że do uzyskania tych samych wyników autorzy doszli w odmienny sposób. Aby lepiej przedstawić przebieg rozumowania, nie uogólniamy wyników, które są bardziej szczegółowe niż załóżenia tej pracy wymagają. Tyczy się to przede wszystkim algorytmu alg2014, ponieważ jest on tylko częścią rozwiązania innego problemu, który jest tematem pracy \cite{CoDF}. Analiza błędu algtymu alg2015 opiera się na badaniu właściowści jego poszczególnych kroków. Oszacowanie błędu dla alg2014 wynika z dokładnej analizy własności wiolomianów Lagrange'a i testu na nich opartego.

    Poniższe twierdzenia prezentują główne właściwości algorytmów.
    
    \begin{thm}[Błąd alg2015] \label{AoP_tw1} ~%
        \begin{enumerate}
            \item $r^{wor}_{p}(n, \delta, \mathcal{F}^{D}_{r,\varrho}) = \Theta(\max(\delta, n^{-(r+\varrho)})) \quad dla \: 1 \leq p \leq \infty$
            \item $r^{wor}_{\infty}(n, \delta, \mathcal{F}^{C}_{r,\varrho}) = \Theta(\max(\delta, n^{-(r+\varrho)}))$
        \end{enumerate}
    \end{thm}

    \begin{thm}[Błąd alg2014]
        \label{2014_tw1}
        Niech $r+\varrho \geq 1$. Istnieją stałe $C$ i $m_{0}$ takie, że dla $m>m_{0}$, przedziału $[a,b]$ oraz wszystkich $g \in \G$ z $\delta_{g}^{0} = 0$ zachodzi:
        \begin{equation*}
            \sup_{t \in [a,b]} \| g(t) - q(t) \| \leq Cm^{-(r+\varrho)}
        \end{equation*}
        Dodatkowo, obliczenie $q$ wymaga $O(p+\log m)$ ewaluacji fun $g$, gdzie $p$ jest liczbą przedziałów w początkowym podziale $M$ przedziału $[a,b]$. Czyli, aby otrzymać optymalną aproksymację $g \in \G$ na przedziale $[a,b]$, wystarcza wiąźć podział $M$ z $m+1$ równoodległymi punktami $x_{i} = a+(b-a)i/m$, dla $i=0,1,\dots,m$. wtedy obliczenie $q$ wymaga $O(m)$ ewaluacji funkcji $g$.
    \end{thm}

\mgrclosechapter


\chapter{Algorytmy}

\section{Algorytm oparty o informację dokładną}

    Algorytm przedstawiony w pracy \cite{CoDF} lokalizuje osobliwość przy pomocy wielomianów Lagrange'a $w_{g}^{r}$. Na wejściu algorytm otrzymuje $g \in \G$, przedział $[a,b]$, regularność $r$ oraz współczynnik Höldera $\varrho$. Kluczowym elementem algorytmu jest zdefiniowana poniżej wielkość (\textit{test}), która jest użyta do wykrycie punktu osobliwego.
    \begin{equation}
        \label{eqn:test}
        A_{g}(a, \bar{a}, \bar{b}, b)=\max _{0 \leq j \leq r} \frac{\left\|w_{g}^{r}([\bar{b}, b])\left(z_{j}\right)-w_{g}^{r}([a, \bar{a}])\left(z_{j}\right)\right\|}{\bar{h}^{r+e}},
    \end{equation}
    gdzie $a<\bar{a}<\bar{b}<b$, $z_{j} = \bar{a} + (\bar{b} - \bar{a})j/r$, dla $j=0,1,\dots,r$ oraz $\bar{h} = b - a$ jest długością przedziału, na którym \textit{test} jest zdefiniowany.

    \vspace{10pt}
    \begin{tabular}{p{0.045\linewidth} p{0.85\linewidth}}
        \textit{K1:}    & Niech $\omega \coloneqq h^{r+\varrho}$, $B \coloneqq \{a, b\}$ \\
                        & \textbf{jeżeli} \(\displaystyle \max_{0 \leq i \leq p-1} (c_{i+1} - c_{i}) \leq 4\omega \) \textbf{wtedy} \\
                        & $\quad$ idź do \textit{Krok 3} \\
                        & \textbf{w p.p.} \\
                        & $\quad$ Niech, dla $j=0,1, \ldots, p-1$, \\
                        & $\quad$ $A=\max \left\{A_{g}\left(c_{j}, c_{j}+\omega, c_{j+1}-\omega, c_{j+1}\right) \mid c_{j+1}-c_{j}>4 \omega\right\}$ \\
                        & $\quad$ Niech $A_{g}^{i} = A_{g}\left(c_{i}, c_{i}+\omega, c_{i+1}-\omega, c_{i+1}\right)$ \\
                        & $\quad$ \textbf{jeżeli} istnieją różne $k$ i $l$ takie, że $A = A^{k} \land A = A^{l}$ \textbf{wtedy} \\
                        & $\quad\quad$ idź do \textit{K3} \\
                        & \\

        \textit{K2:}    & Niech $[c_{k}, c_{k+1}]$ - przedział otrzymany w \textit{K1} oraz niech $[a_{1}, b_{1}] = [a, b]$ \\
                        & \textbf{dopóki} $b_{1} - a_{1} > \omega$ \textbf{wykonuj}: \\
                        & $\quad$Oblicz $v = (a_{1} + b_{1}) / 2$ oraz $B = B \cup \{v\}$ \\
                        & $\quad$\textbf{jeżeli} $A_{g}(a_{1}, a_{1} + \omega, v - \omega, v) = A_{g}(v, v + \omega, b_{1} - \omega, b_{1})$ \textbf{wtedy} \\
                        & $\quad$$\quad$ idź do \textit{K3} \\
                        & $\quad$\textbf{w p.p.} \\
                        & $\quad$$\quad$za następny przedział $[a_{1}, b_{1}]$ wybierz podprzedział $[a_{1}, v]$ lub $[v, b_{1}]$, \\
                        & $\quad$$\quad$dla którego wartość testu była większa \\
                        &  \\

        \textit{K3:}    & Niech $\bar{M} = \left\{ c_{0}, \dots, c_{p} \right\} \cap B$ \\
                        & $q(t)= \begin{cases}
                            g\left(c_{i}\right)                                                 &\text{gdy } t \in \left[c_{i}, c_{i+1}\right) \land c_{i+1}-c_{i} \leq 4 \omega \\ 
                            g\left(c_{i}\right)                                                 &\text{gdy } t \in \left[c_{i}, c_{i}+\omega\right) \land c_{i+1}-c_{i}>4 \omega, \\ 
                            w_{g}^{r}\left(\left[c_{i}+\omega, c_{i+1}-\omega\right]\right)(t)  &\text{gdy } t \in\left[c_{i}+\omega, c_{i+1}-\omega\right) \land c_{i+1}-c_{i}>4 \omega \\ 
                            g\left(c_{i+1}-\omega\right)                                        &\text{gdy } t \in\left[c_{i+1}-\omega, c_{i+1}\right) \land c_{i+1}-c_{i}>4 \omega
                            \end{cases}$ \\
                        & dla $i=0,1,\dots,k-1$ z $q(b) = $ zdefiniowanym przez ciągłość na ostatnim przedziale \\
                        & $B \coloneqq B \cup \left\{ c_{i} + \omega, c_{i+1} - \omega \mid c_{i+1} - c_{i} > 4\omega,\; i=0,\dots,k-1 \right\}$ \\

    \end{tabular} \vspace{10pt}


\section{Algorytm oparty o inforamcję zaburzoną}

    W tym rozdziale opiszemy algorytm bazujący na informacji zaburzonej przedstawiony w artykule \cite{AoP}. Analizowany algorytm używa co najwyżej $n$ wartości funkcji z precyzją $\delta $ oraz w najgorszym przypadku ma błąd proporcjonalny do $\max{(\delta, n^{-1 / r + \varrho })}$ w klasie funkcji $\F^D_{r,\varrho }$ dla $p < \infty$ oraz w klasie $\F^C_{r,\varrho }$ dla $p \leq \infty$. Kluczowym parametrem algorytmu jest
    $$
        h = T / m \quad with \quad  m \geq 2r + 1,
    $$
    gdzie $m$ jest początkową gęstością siatki. Dodatkowo, niech $\omega  = \omega(h)$ spełnia $0 < \omega < (r + 1)h $.

    Na początku algorytm aproksymuje punkt osobliwy $s_f$. Jest to realizowane w trzech krokach. W kroku 1. przy pomocy siatki rozmiarze o długości $h$ i różnic dzielonych lokalizowany jest punkt $s_f$ na przedziale $[u_1, v_1]$ o długości $(r + 1)h$. W kroku 2. używamy wielomianów interpolujących $\tilde{p}_+$ i $\tilde{p}_-$ do zwężenia tego przedziału do $[u_2, v_2]$. Krok 3. produkuje przedział $[u_3, v_3] \subseteq [u_2, v_2]$, w którym różnica $|\tilde{p}_{+} - \tilde{p}_{-}|$ jest nierosnąca na $[u_3, \xi]$ i niemalejąca na $[\xi, v_3]$, gdzie $\xi$ jest finalną aproksymacją $s_f$.

    Powyższe kroki mogą być zapisane następująco; dla $t_i = ih \; \forall i$. \vspace{10pt}

    \noindent
    \begin{tabular}{p{0.10\linewidth} p{0.85\linewidth}}
        
        \textit{Krok 1} & Oblicz różnice dzielone $\tilde{d}_i = \tilde{f}[t_i, \ldots, t_{i+r+1}]$ for $1 \leq i \leq m $ oraz znajdź \\
                        & \(\displaystyle \qquad i^* = arg \max_{1 \leq i \leq m }|\tilde{d}_i| \)  \\
                        & Niech $u_1 = t_{i^*}$ i $v_1 = t_{i^* + r + 1}$. \\
                        & \\

        \textit{Krok 2} & Oznaczymy przez $\tilde{p}_+$ i $\tilde{p}_-$ wielomiany stopnia $ \leq r$, które interpolują węzły $(t_j, \tilde{f}(t_j))$ odpowiednio dla $i^* - r \leq j \leq i^*$ oraz dla $i^* + r + 1 \leq j \leq i^* + 2r + 1$. Następnie wykonaj iterację: \\
                        & $u := u_1$, $v := v_1$ \\
                        & \textbf{dopóki} $v-u > \omega$ \textbf{wykonuj}: \\
                        & $\quad$$z_j := u + j(v-u) / (r+2), \qquad j = 1, 2, \ldots, r + 1$ \\
                        & $\quad$\(\displaystyle j^* := arg \max_{1 \leq j \leq r + 1}|\tilde{p}_{+}(z_j) - \tilde{p}_{-}(z_j)| \) \\
                        & $\quad$\textbf{jeżeli} $|\tilde{f}(z_{j^*}) - \tilde{p}_{-}(z_j)| \leq |\tilde{f}(z_{j^*}) - \tilde{p}_{+}(z_j)|$ \textbf{wtedy} \\
                        & $\quad\quad$$u:= z_{j^*}$ \\
                        & $\quad$\textbf{w p.p.} \\
                        & $\quad\quad$$v:= z_{j^*}$ \\
                        & \textbf{koniec} \\
                        & Niech $u_2 = u$ i $v_2 = v$. \\
                        & \\

        \textit{Krok 3} & Wykonaj iterację: \\
                        & $u := u_2$, $v := v_2$ \\
                        & \textbf{dopóki} istnieje maksimum lokalne $|\tilde{p}_{+} - \tilde{p}_{-}|$ na $(u,v)$ \textbf{wykonuj} \\
                        & $\quad$$z :=$ największe maksimum lokalne $|\tilde{p}_{+} - \tilde{p}_{-}|$ na $(u,v)$ \\
                        & $\quad$\textbf{jeżeli} $|\tilde{f}(z) - \tilde{p}_{-}(z)| \leq |\tilde{f}(z) - \tilde{p}_{+}(z)|$ \textbf{wtedy} \\
                        & $\quad\quad$$u:= z$ \\
                        & $\quad$\textbf{w p.p.} \\
                        & $\quad\quad$$v:= z$ \\
                        & \textbf{koniec} \\
                        & Niech $u_3 = u$ i $v_3 = v$.
    \end{tabular} \vspace{10pt}

    Finalną aproksymacją $s_f$ jest
    \begin{equation*}
            \xi := arg \max_{u_3 \leq x \leq v_3}|\tilde{p}_{+} - \tilde{p}_{-}| \hspace{200pt}
    \end{equation*}

\mgrclosechapter


\chapter{Analiza algorytmów}

    \section{Analiza algorytmu opartego o informację dokładną}

    Zacznijmy od wyjaśnienia własności testu \ref{eqn:test} służącego do wykrywania osobliwości. Rozważmy błąd interpolacji Lagrange'a dla nieciągłej funkcji $g \in \G$. Błąd jest ograniczony za względu na wielomian $s^{g}$ (TODO: reference).

    \begin{lemma}
        Istnieje stała $C$ taka, że dla wszystkich $[a,b]$, wszystkich $g \in \G$ oraz $s=0,1,\dots,r$, mamy
        \begin{equation*}
            \sup _{t \in[a, b]}\left\|g(t)-w_{g}^{s}([a, b])(t)\right\| \leq C\left(\min \left\{\sup_{t \in[a, \hat{t}_{g})}\left\|s_{g}(t)\right\|, \sup _{t \in [\hat{t}_{g}, b]}\left\|s_{g}(t)\right\|\right\}+\bar{h}^{\min \{s+1, r+\varrho\}}\right)
        \end{equation*}
    \end{lemma}
    \begin{proof}
        $(\dots)$
    \end{proof}

    \begin{cor}
        Istnieje stała $C$ taka, że dla wszystkich $[a,b]$, wszystkich $g \in \G$ z $\delta_{g}^{0} = 0$, $0 \leq \delta \leq \min{1, \bar{h}}$ oraz $s=0,1,\dots,r$, mamy
        \begin{equation*}
            \hat{t}_{g} \in(a, a+\delta] \cup[b-\delta, b) \Longrightarrow  \sup_{t \in[a, b]}\left\|g(t)-w_{g}^{s}([a, b])(t)\right\| \leq C\left(\delta+\bar{h}^{\min \{s+1, r+\varrho\}}\right)
        \end{equation*}
    \end{cor}
    \begin{proof}
        $(\dots)$
    \end{proof}

    \begin{lemma}
        Istnieje stała $C$ zależna od $r$ i $L_{r}$ taka, że dla wszystkich $[a,b]$, $\bar{a} \in (a,b)$, wszystkich $g \in \G$, mamy
        \begin{equation*}
            \hat{t}_{g} \in(\bar{a}, b) \Longrightarrow g(t)-w_{g}^{r}([a, \bar{a}])(t)=s_{g}(t) \1_{\left[\hat{t}_{g}, b\right]}(t)+R_{g}(t), \quad t \in[\bar{a}, b],
        \end{equation*}
        gdzie $\| R_{g}(t) \| \leq C\bar{h}^{r+\varrho}$, dla $t \in [\bar{a}, b]$
    \end{lemma}
    \begin{proof}
        $(\dots)$
    \end{proof}

    \begin{cor}
        Istnieje stała $\bar{C}$ zależna od $r$ i $L_{r}$ taka, że dla wszystkich $[a,b]$, $\bar{a} \in (a,b)$, wszystkich $g \in \G$, mamy
        \begin{equation*}
            \hat{t}_{g} \in (a,\bar{a}) \Longrightarrow g(t)-w_{g}^{r}([\bar{a},a])(t)=s_{g}(t) \1_{\left[a,\hat{t}_{g}\right]}(t)+R_{g}(t), \quad t \in[a,\bar{a}],
        \end{equation*}
        gdzie $\| R_{g}(t) \| \leq \bar{C}\bar{h}^{r+\varrho}$, dla $t \in [a,\bar{a}]$
    \end{cor}
    \begin{proof}
        $(\dots)$
    \end{proof}

    \begin{stw}
        \label{2014_stw1}
        Istnieje stała $C^{*}$ zależna od $r$ i $L_{r}$ taka, że dla wszystkich $a < \bar{a} < \bar{b} < b$ i $[a,b]$ oraz wszystich $g \in \G$, mamy
        \begin{equation*}
            \hat{t}_{g} \text{ z niezerowym wielomianem } s_{g} \text{ nie jest w } (a,b) \Longrightarrow A_{g}(a, \bar{a}, \bar{b}, b) \leq C^{*}
        \end{equation*}
    \end{stw}
    \begin{proof}
        $(\dots)$
    \end{proof}

    \begin{uw}
        Stwierdzenie \ref{2014_stw1} pokazuje, że procedura LOCATE-APPROXIMATE wraz z zprocedurą BISECTION, sukcesywnie wybiera przedziały bazując a wartościach testu. Zauważmy, że jeżeli $\hat{t}_{g}$ jest unikalna, to wtedy dla jakiegokolwiek przedziału $[a,b]$, który nie został wybrany, mamy $A_{g}(a, \bar{a}, \bar{b}, b) \leq C^{*}$
    \end{uw}

    \begin{stw}
        \label{2014_stw2}
        Niech $D > 0$. Istnieją stałe $C$ i $\bar{N}$, zależne tylko od parametrów klast $\G$ i $D$, takie, że dla wszystkich $[a,b]$, $[\bar{a}, \bar{b}] \subset (a,b)$, $g \in \G$ oraz $s=0,1,\dots,r$, mamy
        \begin{equation*}
            \hat{t}_{g} \in (\bar{a}, \bar{b}] \land b-a \leq D(\bar{b}-\bar{a}) \Longrightarrow \text{dla } [\gamma, \omega]=[a, b] \vee [\gamma, \omega]=[\bar{a}, \bar{b}] \text{ zachodzi }
        \end{equation*}
        \begin{equation*}
            \sup _{t \in[\gamma, \omega]}\left\|g(t)-w_{g}^{s}([\gamma, \omega])(t)\right\| \leq C\left(1+A_{g}(a, \bar{a}, \bar{b}, b)\right) \bar{h}^{\min \{s+1, r+\varrho\}}
        \end{equation*}
        oraz ponadto
        \begin{equation*}
            \sup _{t \in[\gamma, \omega]}\left\|\left(w_{g}^{s}([\gamma, \omega])\right)^{(j)}(t)\right\| \leq \bar{N}\left(1+\bar{h}^{\min \{s+1-j, r+\rho-j\}}+\left(1+A_{g}(a, \bar{a}, \bar{b}, b)\right) \bar{h}^{r+\varphi-j}\right)
        \end{equation*}
        dla $j=0,1,\dots,s$.
    \end{stw}
    \begin{proof}
        $(\dots)$
    \end{proof}

    \begin{uw}
        Stwierdzenie \ref{2014_stw2} pokazuje, że w przypadku z osobliwością, ograniczenie górne na błąd interpolacji możemy wyrazić za pomocą $A_{g}(a, \bar{a}, \bar{b}, b)$
    \end{uw}

    Poniższy lemat dotyczy przypadku, gdy osobliwość znajduje się na brzegu przdziału $[a,b]$\\
    \textit{(lemat... dowod...)}

    \textit{(Dowód tw1 z 2014)}

    \begin{uw}
        Twierdzenie \ref{2014_tw1} zachodzi również dla funkcji $g$, która ma skok w punkcie $c_{i}$ początkowego podziału $M$ oraz ma niezerowy wielomian $s_{g}$ dla co najwyżej jednego nieznanego punktu $t_{g}$, $t_{g} \neq c_{i} \; \forall_{i}$.
    \end{uw}


    \section{Analiza algorytmu opartego o informację zaburzoną}

    Niech $m \geq 2r + 1$, $h + \frac{T}{m}$ oraz $t_{i} = ih$ dla każdego $i$. Przez $d_{i}$ oznaczmy różnicę dzieloną stopnia $r+1$ bazującą na wartościach $f(t_{i})$:
    \begin{equation*}
        d_{i} = f[t_{i}, \dots, t_{i+r+1}] = \sum_{j = 1}^{i+r+1} \gamma_{j} \prod_{k=1 \land k \neq j}^{i+r+1}(t_{k}-t_{j})^{-1}
    \end{equation*}

    Następnie oznaczmy przez $\tilde{d_i}$ (niedokładną) różnicę dzieloną stopnia $r+1$ bazującą na wartościach $y_{j} = F(t_{j}) + e_{j}$, gdzie $|e_{j}| \leq \delta$
    \begin{equation*}
        \tilde{d_{i}} = \tilde{f}[t_{i}, \dots, t_{i+r+1}] = \sum_{j = 1}^{i+r+1} \gamma_{j} \prod_{\substack{k=1 \\ k \neq j}}^{i+r+1}(t_{k}-t_{j})^{-1}
    \end{equation*}

    \begin{lemma}
        Jeżeli $f \in H_{r, \varrho}(t_{i}, t_{i+r+1})$, wtedy
        \begin{equation*}
            |\tilde{d_{i}}| \leq \frac{c(g_{f})(r+1)^{\varrho}}{(r+1)!} h^{\varrho-1} + \delta \frac{2^{r+1}}{(r+1)!} h^{-(r+1)}
        \end{equation*}
    \end{lemma}
    \begin{proof}
        Korzystając z nierówności trójkąta $|\tilde{d_{i}}|  \leq |d_{i}| + |\tilde{d_{i}} - d_{i}|$ możemy oszacować pierwszy człon:
        \begin{equation}
            \begin{aligned}
            \left|d_{i}\right| &=\frac{\left|f\left[x_{i+1}, \ldots, x_{i+r+1}\right]-f\left[x_{i}, \ldots, x_{i+r}\right]\right|}{x_{i+r+1}-x_{i}} 
                = \frac{1}{r !} \frac{\left|f^{(r)}\left(\xi_{1}\right)-f^{(r)}\left(\xi_{2}\right)\right|}{x_{i+r+1}-x_{i}} \\
            & \leq \frac{c\left(g_{f}\right)}{r !} \frac{\left|\xi_{1}-\xi_{2}\right|^{\varrho}}{x_{i+r+1}-x_{i}} 
                \leq \frac{c\left(g_{f}\right)}{r !}\left(x_{i+r+1}-x_{i}\right)^{\varrho-1} 
                \leq \frac{c\left(g_{f}\right)(r+1)^{\varrho}}{(r+1) !} h^{\varrho-1}
            \end{aligned}
        \end{equation}
        oraz drugi człon:
        \begin{equation}
            \begin{aligned}
            \left|\tilde{d}_{i}-d_{i}\right| & =h^{-(r+1)}\left|\sum_{i=0}^{r+1} e_{i} \prod_{\ell=0 \atop \ell \neq i}^{r+1}(\ell-j)^{-1}\right| \\
            & \leq \delta h^{-(r+1)} \sum_{i=0}^{r+1} \prod_{\ell=0 \atop \ell \neq i}^{r+1}|\ell-j|^{-1}=\delta \frac{2^{r+1}}{(r+1) !} h^{-(r+1)}
            \end{aligned}
        \end{equation}
        co dowodzi lemta.
    \end{proof}

    Teraz oszacujemy błąd interpolacji i ekstrapolacji w obecności zaburzenia wartości funkcji. Niech $p_{i}$ i $\tilde{p_{i}}$ odpowiadają wielomianom stopnia co najwyżej $r$ interpolujących $f$ opartych na dokładnych i niedokładnych wartościach funkcji $f$ w punktach $t_{i}, t_{i+1}, \dots, t_{i+r}$. Dla $r \geq 1$, wprowadźmy oznaczenia:
    \begin{equation*}
        \beta_{r} = \max_{0 \leq t \leq r} \left|\prod_{k=0}^{r} (t-k)\right|, \quad
        \Lambda_{r} = \max_{0 \leq t \leq r} \sum_{k=0}^{r} \prod_{\substack{l=0 \\ l \neq k}}^{r} \left| \frac{t-l}{k-l} \right| \quad
        \tilde{\Lambda}_{r} = \sum_{k=0}^{r} \prod_{\substack{l=0 \\ l \neq k}}^{r} \left| \frac{2r+1-l}{k-l} \right|
    \end{equation*}

    \begin{lemma}
        Niech $f \in H_{0, \varrho}$, wtedy: \\
        $dla \; x \in [t_{i-\frac{1}{2}}, t_{i + \frac{1}{2}}] :$
        \begin{equation*}
            |f(x) - \tilde{p}_{1}(x)| \leq C_{0, \varrho}(f) h^{\varrho} + \delta, \quad C_{0, \varrho}(f) = c(g_{f}) 2^{-\varrho} \\
        \end{equation*}
        $dla \; x \in [t_{i-1}, t_{i - \frac{1}{2}}) \cup (t_{i + \frac{1}{2}}, t_{i+1}]  :$
        \begin{equation*}
            |f(x) - \tilde{p}_{i}(x)| \leq \overline{C} _{0, \varrho}(f) h^{\varrho}  + \delta, \quad \overline{C} _{0, \varrho}(f) = c(g_{f}) \\
        \end{equation*}
        Niech $f \in H_{r, \varrho}$ i $r \geq 1$, wtedy: \\
        $dla \; x \in [t_{i}, t_{i + r}] : $
        \begin{equation*}
            |f(x) - \tilde{p}_{i}(x)| \leq C_{r, \varrho}(f) h^{r+\varrho} + \delta\Lambda_{r}, \quad C_{r, \varrho}(f) = c(g_{f}) 2^{-\varrho} \\
        \end{equation*}
        $dla \; x \in [t_{i-r-1}, t_{i}) \cup (t_{i + r}, t_{i+2r+1}]  :$
        \begin{equation*}
            |f(x) - \tilde{p}_{i}(x)| \leq \overline{C} _{r, \varrho}(f) h^{r+\varrho} + \delta\overline{\Lambda}_{r}, \overline{C} _{r, \varrho}(f) = c(g_{f}) \frac{(2r+1)!(2r+1)^{\varrho}}{r(r!)^{2}} \\
        \end{equation*}
    \end{lemma}

    \begin{proof}
        Przypadek dla $r=0$ jest oczywisty. Niech $r \geq 1$, korzystając z nierównośći trójkąta:
        \begin{equation*}
            \left|f(x)-\tilde{p}_{i}(x)\right| \leq\left|f(x)-p_{i}(x)\right|+\left|\tilde{p}_{i}(x)-p_{i}(x)\right|
        \end{equation*}
        Jeżeli $x \in\left[t_{i}, t_{i+r}\right]$, wtedy dla pierwszego członu powyższej sumy mamy:
        \begin{equation*}
            \begin{aligned}
                \left|f(x)-p_{i}(x)\right| &=\left|\left(x-t_{i}\right) \cdots\left(x-t_{i+r}\right) f\left[t_{i}, \ldots, t_{i+r}, x\right]\right| \\
                & \leq \beta_{r} h^{r+1} \frac{\left|f\left[t_{i+1}, \ldots, t_{i+r}, x\right]-f\left[t_{i}, \ldots, t_{i+r-1}, x\right]\right|}{t_{i+r}-t_{i}} \\
                & \leq \beta_{r} h^{r+1} \frac{c\left(g_{f}\right)}{r^{1-\varrho} r !} h^{\varrho-1}=C_{r, \varrho}(f) h^{r+\varrho}
            \end{aligned}                
        \end{equation*}
        a dla drugiego człony mamy:
        \begin{equation} \label{eq:1}
            \left|\tilde{p}_{i}(x)-p_{i}(x)\right|=\left|\sum_{k=i}^{i+r} e_{k} \prod_{\ell=i \atop \ell \neq k}^{i+r} \frac{x-t_{\ell}}{t_{k}-t_{\ell}}\right| \leq \delta \Lambda_{r}            
        \end{equation}
        Przypadek dla $x \in \left[ t_{i-r-1}, t_{i} \right) \cup \left( t_{i+r}, t_{i+2r+1} \right]$ jest analogiczny.
    \end{proof}

    \begin{lemma}
        Niech $f \in F_{r, \varrho}$ oraz 
        \begin{equation*}
            s_{f} \in 
            \left\{
                \begin{array}{ll}
                    (t_{i-\frac{1}{2}}, t_{i + \frac{1}{2}}], \; gdy \; r=0 \\
                    (t_{i}, t_{i - r}], \; gdy \; r \geq 0    
                \end{array}
            \right.
        \end{equation*}
        Przypuśćmy, że 
        \begin{equation} \label{eq:2}
            |\tilde{d}_{k}| \leq Bh^{\varrho-1} \; \forall_{k}.
        \end{equation}
        Wtedy dla każdego $x \in [t_{i-1}, t_{i+1}]$, gdy $r=0$ lub dla każdego $x \in [t_{i-r-1}, t_{i+2r+1}]$, gdy $r \geq 1$, mamy:
        \begin{equation*}
            |f(x) - \tilde{p}_{i}(x)| \leq D_{r}(B, f)h^{r+\varrho} + \delta\Lambda_{r},
        \end{equation*}
        gdzie $D_{0}(B,f) = c(g_{f}) + B$ i
        \begin{equation*}
            D_{r}(B, f)=c\left(g_{f}\right) \frac{\beta_{r}(r+1)^{\varrho}}{r r !}+B\left(2^{r+1}-1\right) \frac{(2 r) !}{(r-1) !} \quad \text { for } r \geq 1 .
        \end{equation*}
    \end{lemma}
    \begin{proof}
        Przypadki, gdy $s_{f} \leq x$ i $s_{f} > x$ są analogiczne. Weźmy $s_{f} \leq x$. Jeżeli $r=0$, wtedy
        \begin{equation*}
            \begin{aligned}
                \left|f(x)-\tilde{p}_{i}\right| & \leq\left|f(x)-p_{i+1}\right|+\left|p_{i+1}-\tilde{p}_{i+1}\right|+\left|\tilde{p}_{i+1}-\tilde{p}_{i}\right| \\
                & \leq c\left(g_{f}\right) h^{\varrho}+\delta+B h^{\varrho}=\left(c\left(g_{f}\right)+B\right) h^{\varrho}+\delta
            \end{aligned}    
        \end{equation*}
        Pokazaliśmy pierwszą część lematu.
        Załóżmy, że $r \geq 1$ i $s_{f} \leq x<t_{i+r}$. Wybierzmy najmniejszy indeks $j$ taki, że $s_{f} \leq t_{j}$. Oczywiście $i+1 \leq j \leq i+r$ oraz $x \in\left[t_{j-1}, t_{j+r}\right]$. 
        Otrzymujemy
        \begin{equation} \label{eq:6}
            \left|f(x)-\tilde{p}_{i}(x)\right| \leq\left|f(x)-p_{j}(x)\right|+\left|p_{j}(x)-\tilde{p}_{j}(x)\right|+\left|\tilde{p}_{j}(x)-\tilde{p}_{i}(x)\right|
        \end{equation}
        A ponieważ $s_{f} \notin\left(t_{j}, t_{j+r}\right]$, to
        \begin{equation*}
            \left|f(x)-p_{j}(x)\right| \leq c\left(g_{f}\right) \beta_{r} h^{r+1} \frac{1}{r !} \frac{\left(t_{j+r}-t_{j-1}\right)^{\varrho}}{t_{j+r}-t_{j}}=C_{r, \varrho}(f)\left(1+\frac{1}{r}\right)^{\varrho} h^{r+\varrho}
        \end{equation*}
        Tak jak w równaniu \ref{eq:1}, mamy
        \begin{equation*}
            \left|p_{j}(x)-\tilde{p}_{j}(x)\right| \leq \delta \Lambda_{r}            
        \end{equation*}
        Możemy tearz oszacować pozostały człon $\left|\tilde{p}_{j}(x)-\tilde{p}_{i}(x)\right|$. Dla $i+r+1 \leq k \leq j+r$, mamy
        \begin{equation} \label{eq:3}
            \left(\tilde{f}-\tilde{p}_{i}\right)\left[t_{i}, \ldots, t_{i+r}, t_{k}\right]=\frac{y_{k}-\tilde{p}_{i}\left(t_{k}\right)}{(k-i)(k-i-1) \cdots(k-i-r) h^{r+1}}
        \end{equation}
        oraz
        \begin{equation} \label{eq:4}
            \left|\left(\tilde{f}-\tilde{p}_{i}\right)\left[t_{i}, \ldots, t_{i+r}, t_{k}\right]\right|=\left|\tilde{f}\left[t_{i}, \ldots, t_{i+r}, t_{k}\right]\right| \leq \max _{i \leq \ell \leq k-r-1}\left|\tilde{d}_{\ell}\right| \leq B h^{Q-1}            
        \end{equation}
        gdzie pierwsza nie równość wynika z \cite{UA}(Lemat 1), natomiast druga z \ref{eq:2}. Biorąc \ref{eq:3} oraz \ref{eq:4}, otrzymujemy:
        \begin{equation} \label{eq:5}
            \left|y_{k}-\tilde{p}_{i}\left(t_{k}\right)\right| \leq \frac{(2 r) !}{(r-1) !} B h^{r+\varrho}
        \end{equation}

        Także ostatni człon nierówności \ref{eq:6} możemy oszacować następująco

        \begin{equation*}
            \begin{aligned}
                \left|\tilde{p}_{j}(x)-\tilde{p}_{i}(x)\right| &=\left|\sum_{k=j}^{j+r}\left(\tilde{p}_{j}\left(t_{k}\right)-\tilde{p}_{i}\left(t_{k}\right)\right) \prod_{\ell=j \atop \ell \neq k}^{j+r} \frac{x-t_{\ell}}{t_{k}-t_{\ell}}\right| \\
                & \leq\left(\max _{j \leq k \leq j+r}\left|y_{k}-\tilde{p}_{i}\left(t_{k}\right)\right|\right)\left(\max _{0 \leq t \leq r+1} \sum_{k=0}^{r} \prod_{\ell=0 \atop \ell \neq k}^{r}\left|\frac{t-\ell}{k-\ell}\right|\right)
            \end{aligned}                
        \end{equation*}
        Pierwsze maksimum z powyższego równania jest oszacowane poprzez \ref{eq:5}. Natomiast drugie maksimum jest osiągane dla $t=r+1$ i jest równe
        \begin{equation*}
            \sum_{k=0}^{r} \prod_{\ell=0 \atop \ell \neq k}^{r}\left|\frac{r+1-\ell}{k-\ell}\right|=\sum_{k=0}^{r}\left(\begin{array}{c} r+1 \\ k\end{array}\right)=2^{r+1}-1
        \end{equation*}
        Stąd
        \begin{equation*}
            \left|\tilde{p}_{j}(x)-\tilde{p}_{i}(x)\right| \leq \frac{(2 r) !}{(r-1) !}\left(2^{r+1}-1\right) B h^{r+\varrho}
        \end{equation*}
    \end{proof}

    %%%%%%%%%%%%%%%%%

    Przedstawiony algorytm używa $m$ wartości funkcji w kroku 1 oraz jedyną wartość funkcji w każdej iteracji w krokach 2 i 3. Czyli w kroku 2 używamy co najwyżej
    \begin{equation*}
        \left\lceil\frac{\ln \left(\frac{(r+1) h}{\omega(h)}\right)}{\ln \left(\frac{r+2}{r+1}\right)}\right\rceil
    \end{equation*}
    wartości funkcji i $(r-1)$ w kroku 3.
    Stąd otrzymujemy, że jeżezli $\omega = \omega(h) \geq kh^{\alpha}$ dla pewngo ustalonego $k$ i $\alpha$, wtedy w najgoryszym przypadku liczba użytych wartości funkcji równa sie asymptotycznie $m = \frac{T}{h}$ dla $h \rightarrow 0^{+}$. \\


    \textit{(punktowa analiza błędu...)}

    Podsumowując analizę błędu dla każdego punktu otrzymujemy, że gdy $\delta \leq bh^{r+\varrho}$ wtedy:
    \begin{equation*}
        \begin{cases}
            |f(x) - \phi_{h}^{*}(y_{h})(x)| \propto \max(1, c(g_{f})) h^{r+\varrho} & \text{ dla } x \notin (u_{2}, v_{2}] \\
            |f(x) - \phi_{h}^{*}(y_{h})(x)| \propto \max(1, c(g_{f})) h^{r+\varrho} + |\Delta_{f}^{(0)}| & \text{ dla } x \in (u_{2}, v_{2}] \\
        \end{cases}
    \end{equation*}
    gdzie $v_{2} - u_{2} \leq \omega$

    Mamy również, że liczba ewaluacji funkcji $n$ jest proporcjonalna do $h^{-1}$, tak więc $h^{r+\varrho}$ jest proporcjonalne do $n^{-(r+\varrho)}$. Z tego wynika poniższe stwierdzenia:
    \begin{stw}
        \label{stw2}
        Niech $1 \leq p \leq \infty$. Jeżeli $\delta \leq bh^{r+\varrho}$ oraz $\omega(h) = h^{(r+\varrho)p + 1}$, wtedy
        \begin{equation*}
            e_{\mathrm{p}}^{wor}\left(\varphi_{h}^{*}, N_{h}^{*} ; \mathcal{F}_{r, \varrho}^{D}\right)=\mathcal{O}\left(n^{-(r+\varrho)}\right)
        \end{equation*}
    \end{stw}

    Warto wspomnieć, że powyższe ograniczenia górne nie może zostać spełnione przez algorytmy nieadaptacyjne, co zostało pokazane w \cite{PoA}. Pokazano tam również, że dla $p=\infty$ nie istnieje algorytm z błędem zbiegającym do zera, dlatego założenia $p < \infty$ jest niezbędne. Dodatkowo, gdy rozważymy klasę $\mathcal{F}_{r, \varrho}^{C} \subset \mathcal{F}_{r, \varrho}^{D}$, to możemy uprościć algorytm biorąc $\omega(h) = (r+1)h$ i unikając iteracji w kroku 2. Otrzymujemy w ten sposób algorytm, który dla $r=0,1$ jest nieadaptacyjny, a dla $r \geq 2$ używa co najwyżej $r-1$ dodatkowych punktów, niezależnie od tego jak małe jest $h$. Co więcej, organiczenie górne zachodzi dla $p = \infty$
    Stosując powyższą modyfikację możemy sformułować następujące stwierdzenie.

    \begin{stw}
        \label{stw3}
        Jeżeli $\delta \leq bh^{r+\varrho}$ i $\omega(h) = (r+1)h$, wtedy:
        \begin{equation}
            \mathrm{e}_{\infty}^{\mathrm{wor}}\left(\varphi_{h}^{*}, N_{h}^{*} ; \mathcal{F}_{r, \varrho}^{C}\right)=\mathcal{O}\left(n^{-(r+\varrho)}\right) .
        \end{equation}
    \end{stw}

    Ponownie, dla $r \geq 2$ użycie informacji adaptacyjnej jest konieczne. Łącząc wyniki \ref{stw2}, \ref{stw3} i \ref{stw1}\ref{stw1_i} otrzymujemy \ref{AoP_tw1}.
    Faktycznie, dla ustalonego $\delta$ i $n$ możemy wybrać $h = \frac{T}{m}$ takie, że
    \begin{equation}
        m = m(n, \delta)=\left\lfloor\min \left(\beta n, \frac{1}{T}\left(\frac{b}{\delta}\right)^{\frac{1}{r+\varrho}}\right)\right\rfloor=\varTheta\left(\min \left(n, \delta^{-1 /(r+\varrho)}\right)\right),
    \end{equation}

    \begin{uw}
        Zauważmy, że dla ustalonej precyzji $\delta$ nie ma sensu brać $m$ większego niż $m_{max} = \varTheta(\delta^{-1 / (r+\varrho)})$ wartości funkcji, ponieważ dla $m = m_{max}$ osiągamy maksymalną dokładność dla danego $\delta$.
    \end{uw}

\mgrclosechapter


\chapter{Testy numeryczne}

porównanie algorytmów

\mgrclosechapter


%%
%% ======== BIBLIOGRAFIA ========
%%

%% <<<< BiBTeX >>>>
% \bibliography{<pliki bib>} 
%%
\begin{thebibliography}{88}

    \bibitem{IaA}
    F. Arandiga, A. Cohen, R. Donat, N. Dyn,
    \emph{Interpolation and approximation of piecewise smooth functions}, SIAM J. Numer. Anal. 43 (2005) 41–57

    \bibitem{PoA}
    L. Plaskota, G. W. Wasilkowski, Y. Zhao, 
    \emph{The power of adaption for approximating functions with singularities}, Mathematics Of Computation 77
    2008, p. 2309–2338

    \bibitem{UA}
    L. Plaskota, G. W. Wasilkowski, 
    \emph{Uniform approximation of piecewise r-smooth and globally continuous functions}, SIAM Journal on Numerical
    Analysis, Vol. 47, No. 1 (2008/2009)

    \bibitem{CoDF}
    B. Kacewicz, P. Przybyłowicz, 
    \emph{Complexity of the derivative-free solution of
    systems of IVPs with unknown singularity hypersurface}, Journal of Complexity
    
    \bibitem{AoP}
    P. M. Morkisz, L. Plaskota, 
    \emph{Approximation of piecewise Hölder functions from inexact information}, Journal of Complexity

    \bibitem{Ibc}
    J. F. Traub, H. Woźniakowski, G. W. Wasilkowski
    \emph{Information-Based Complexity}, Academic Press, New York, 1988

\end{thebibliography}

\end{document}
